{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kai0127/Jupyter-Notebooks/blob/master/intro_to_ml_hw4_recitation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decision Tree\n",
        "\n",
        "First part of the homework required you to read the data and fit a decision tree by using sklearn libraries.\n",
        "We will use: \n",
        "1. `sklearn.tree.DecisionTreeClassifier` to fit tree to the data.\n",
        "2. We will load the data in https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data by using pandas library. \n",
        "3. Finally we'll fit a tree to the data at each iteration."
      ],
      "metadata": {
        "id": "u8ipDmmhN3bZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n"
      ],
      "metadata": {
        "id": "tCzA1NHPNuiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_seeds = [i for i in range(20)]\n",
        "criterion = 'gini' #gini, entropy, log_loss\n",
        "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data', header=None, index_col=57) # Number of attributes in the dataset is 57"
      ],
      "metadata": {
        "id": "9DnyR20AOifx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the training loop\n",
        "# For each seed we will be splitting the data, fit the tree and get the accuracy\n",
        "accuracies = []\n",
        "for random_seed in random_seeds: \n",
        "    # Get the data and fit a classifier\n",
        "    X_train, X_test, y_train, y_test = train_test_split(data, data.index.values, test_size=0.3, random_state=random_seed)\n",
        "    classifier = DecisionTreeClassifier(splitter='random', random_state=random_seed)\n",
        "    classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Predict\n",
        "    y_pred = classifier.predict(X_test)\n",
        "\n",
        "    # Get the accuracy score\n",
        "    accuracies.append(accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "_qYozNz7O00q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the maximum accuracy\n",
        "accuracies = np.array(accuracies)\n",
        "print(f'Decision Tree Max accuracy: {accuracies.max()}\\tCriterion: {criterion}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STnJVHuuPuQh",
        "outputId": "c2af322e-2156-4b2f-cb10-47388a782910"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Max accuracy: 0.9254163649529327 with criterion: gini\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest\n",
        "\n",
        "Now we will again use already implemented random forest classifiers with different seeds each.\n",
        "Very similar to decision trees only with multiple estimators and taking their advantage."
      ],
      "metadata": {
        "id": "tBjOizjSQATW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "9cBDSgJ7ljzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_estimators = [1, 3, 5, 10, 15, 20, 40, 70]\n",
        "random_states = [i for i in range(20)]\n",
        "criterion = 'entropy' # gini, entropy, log_loss\n",
        "\n",
        "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data', header=None, index_col=57)"
      ],
      "metadata": {
        "id": "pzO-RWMplxPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for n in n_estimators:\n",
        "    precision = []\n",
        "    recall = []\n",
        "    accuracies = []\n",
        "    for random_state in random_states:\n",
        "        # Sample the dataset\n",
        "        X_train, X_test, y_train, y_test = train_test_split(data, data.index.values, test_size=0.3, random_state=random_state)\n",
        "\n",
        "        # Fit\n",
        "        classifier = RandomForestClassifier(n_estimators=n, criterion=criterion, random_state=random_state)\n",
        "        classifier.fit(X_train, y_train)\n",
        "\n",
        "        # Predict\n",
        "        y_pred = classifier.predict(X_test)\n",
        "\n",
        "        # Evaluate\n",
        "        accuracies.append(accuracy_score(y_test, y_pred))\n",
        "        \n",
        "    accuracies = np.array(accuracies)\n",
        "    print(f\"Random Forest Max Accuracy: {accuracies.max()}\\tn_estimator:{n}\\tCriterion: {criterion}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szWhlIlOl0hC",
        "outputId": "de2b7210-8ab8-45b0-c9a3-254534011d2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Max Accuracy: 0.9232440260680667\tn_estimator:1\tCriterion: entropy\n",
            "Random Forest Max Accuracy: 0.9478638667632151\tn_estimator:3\tCriterion: entropy\n",
            "Random Forest Max Accuracy: 0.9572773352643013\tn_estimator:5\tCriterion: entropy\n",
            "Random Forest Max Accuracy: 0.9630702389572773\tn_estimator:10\tCriterion: entropy\n",
            "Random Forest Max Accuracy: 0.9623461259956553\tn_estimator:15\tCriterion: entropy\n",
            "Random Forest Max Accuracy: 0.9623461259956553\tn_estimator:20\tCriterion: entropy\n",
            "Random Forest Max Accuracy: 0.9688631426502534\tn_estimator:40\tCriterion: entropy\n",
            "Random Forest Max Accuracy: 0.9695872556118754\tn_estimator:70\tCriterion: entropy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decision Tree from Scratch\n",
        "\n",
        "In this part we're going to be implementing a decision tree from scratch. \n",
        "We will have following parts: \n",
        "1. Reading train and test data. We'll have one `read_data` function for this. \n",
        "2. `Node` class. Representing each split in the decision tree. \n",
        "3. Implement entropy calculationg and information gain for each tree node.\n",
        "4. Method to build the tree.\n"
      ],
      "metadata": {
        "id": "sOIl_t98mZdA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math"
      ],
      "metadata": {
        "id": "jsWlrSNZsauf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading test and train data and dump it to a numpy array\n",
        "def read_data(filename):\n",
        "    data = []  # to store training data from csv file\n",
        "    file_data = []\n",
        "\n",
        "    # Read data from csv\n",
        "    with open(filename,\"r\") as csv_data:\n",
        "        file_data = csv_data.read().split('\\n')\n",
        "\n",
        "    print(f'File data: {file_data}')\n",
        "    for i in range(len(file_data)-1):\t\n",
        "        row = file_data[i].split(',')\n",
        "        for i in range(len(row)):\n",
        "            row[i] = int(row[i])\n",
        "        data.append(row)\n",
        "    data = np.asarray(data)\n",
        "    return data"
      ],
      "metadata": {
        "id": "S6Kt8NV7mVCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = read_data('data2.csv')\n",
        "X_train, y_train = train_data[:,:8], train_data[:,8]\n",
        "X_test = read_data('test2.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWilN_Z5o_3d",
        "outputId": "d1660ef0-c139-46ca-c1a5-287cab872a0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File data: ['1,1,1,1,1,1,0,1,1', '1,1,1,1,1,1,0,0,1', '0,1,1,1,1,1,1,1,0', '1,1,1,1,1,0,0,1,1', '1,1,1,1,1,0,0,0,1', '1,1,1,0,1,1,0,1,1', '0,1,0,1,1,1,0,1,0', '1,1,1,0,1,1,0,0,1', '1,1,1,0,1,0,0,1,1', '1,1,1,0,1,0,0,0,1', '0,1,1,1,1,1,0,1,1', '0,1,1,1,1,1,0,0,1', '0,0,1,1,1,1,0,1,0', '0,1,1,1,1,0,0,1,1', '0,1,0,1,0,1,0,1,0', '0,0,0,1,1,1,0,1,0', '0,0,0,1,0,1,1,1,0', '0,1,1,1,1,0,0,0,1', '0,0,1,1,1,1,1,1,0', '0,1,1,0,1,1,0,1,1', '0,0,1,1,0,1,1,1,0', '0,0,0,1,0,1,1,1,0', '1,1,1,0,1,0,1,1,1', '1,1,0,0,1,0,1,1,1', '']\n",
            "File data: ['0,1,1,1,1,1,1,1', '1,0,0,0,0,0,0,0', '0,1,1,0,1,0,0,0', '0,1,1,1,1,0,0,0', '']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape, y_train.shape, X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCUtYZGkpLSU",
        "outputId": "e4ff470f-24ee-4400-add5-14214864bd3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(24, 8) (24,) (4, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcualate entropy for those labels\n",
        "def entropy(labels):\n",
        "\tsize = len(labels)\n",
        "\tif size == 0: \n",
        "\t\treturn 0\n",
        "\n",
        "\tprob_one = 0\n",
        "\tprob_zero = 0\n",
        "\n",
        "\tfor i in labels:\n",
        "\t\tif i == 1:\n",
        "\t\t\tprob_one += 1\n",
        "\n",
        "\t\telif i == 0:\n",
        "\t\t\tprob_zero += 1\n",
        "\n",
        "\tprob_one = float(prob_one)/size\n",
        "\tprob_zero = float(prob_zero)/size\n",
        "\n",
        "\tif prob_zero == 0 or prob_one == 0:\n",
        "\t\tentropy = 0\n",
        "\n",
        "\telse:\n",
        "\t\tentropy = -prob_zero*math.log(prob_zero,2) - prob_one*math.log(prob_one,2)\n",
        "\n",
        "\treturn entropy"
      ],
      "metadata": {
        "id": "gkqafqBssWiy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "entropy(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojRRKgxuvOg6",
        "outputId": "c726bc9d-5ab3-4afe-f108-63b9ef6255ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9544340029249649"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate information gain with a given attribute split\n",
        "def info_gain(train_data, labels, att_id): # att_id: attribute index to consider\n",
        "    node_entropy = entropy(labels)\n",
        "    attributes = train_data[:,att_id]\n",
        "\n",
        "    # Get all the labels with this attribute being 0\n",
        "    att_zero = labels[attributes == 0]\n",
        "    att_zero_count = len(att_zero)\n",
        "\n",
        "    # Get all the labels with this attribute being 1\n",
        "    att_one = labels[attributes == 1]\n",
        "    att_one_count = len(att_one)\n",
        "\n",
        "    # Calculate the gain\n",
        "    gain = node_entropy - (float(att_zero_count)/len(labels))*entropy(att_zero) - (float(att_one_count)/len(labels))*entropy(att_one)\n",
        "\n",
        "    return gain"
      ],
      "metadata": {
        "id": "FLslO9fNvLW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Traverse through the possible attributes and find the attribute that gives\n",
        "# the maximum information gain\n",
        "def max_info_gain(train_data, labels):\n",
        "    idx = -1\n",
        "    max_gain = -1\n",
        "\n",
        "    att_idx = [i for i in range(len(train_data[0])) if i not in att_used]\n",
        "    for att_id in att_idx:\n",
        "        gain = info_gain(train_data, labels, att_id)\n",
        "        if gain > max_gain:\n",
        "            max_gain = gain\n",
        "            idx = att_id\n",
        "\n",
        "    return idx"
      ],
      "metadata": {
        "id": "Vi50JJUNwjGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Class for one Node\n",
        "class Node: \n",
        "    def __init__(self, train_data, labels): # Gets the attributes and the label given for that node\n",
        "        self.left = None        # for zero\n",
        "        self.right = None       # for one\n",
        "\n",
        "        if entropy(labels) == 0: # Means there is only one label on that node \n",
        "            if labels[0] == 1:\n",
        "                self.att_id = 'Y' # Y means \n",
        "            elif labels[0] == 0:\n",
        "                self.att_id = 'N'\t\n",
        "\n",
        "        else:\n",
        "            self.att_id = max_info_gain(train_data, labels)\t\n",
        "            att_used.append(self.att_id)"
      ],
      "metadata": {
        "id": "-kYa6jS7pOQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_tree(node, train_data, labels):\n",
        "\tif len(att_used) >= len(train_data[0]): # If all the attributes were already used\n",
        "\t\treturn\n",
        "\n",
        "\telif node.att_id == 'Y' or node.att_id == 'N':\n",
        "\t\treturn\t\n",
        "\n",
        "\telse:\t\n",
        "\t\tleft_data = np.reshape(np.extract(np.repeat(np.expand_dims((train_data[:,node.att_id] == 0), axis=1), len(train_data[0]), axis=1), train_data), [-1,train_data.shape[1]])\n",
        "\t\tleft_label = np.reshape(np.extract(train_data[:,node.att_id] == 0, labels), [-1,1]) # Get all the remaining attributes \n",
        "\t\tright_data = np.reshape(np.extract(np.repeat(np.expand_dims((train_data[:,node.att_id] == 1), axis=1), len(train_data[0]), axis=1), train_data), [-1,train_data.shape[1]])\n",
        "\t\tright_label = np.reshape(np.extract(train_data[:,node.att_id] == 1, labels), [-1,1])\t\t\n",
        "\n",
        "\tnode.left = Node(left_data, left_label)\n",
        "\tnode.right = Node(right_data, right_label)\n",
        "\tcreate_tree(node.left, left_data, left_label)\n",
        "\tcreate_tree(node.right, right_data, right_label)\n",
        "\n",
        "\treturn node"
      ],
      "metadata": {
        "id": "-fUda4UTxkIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(root, test_sample):\n",
        "\tnode = root\n",
        "\twhile(node.att_id != 'Y' and node.att_id != 'N'):\n",
        "\t\tif(test_sample[node.att_id] == 0):\n",
        "\t\t\tnode = node.left\n",
        "\t\telse: \n",
        "\t\t\tnode = node.right\n",
        "\t\t\n",
        "\treturn node.att_id"
      ],
      "metadata": {
        "id": "mjcWnxzSx859"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "att_used = []\n",
        "root = Node(X_train, y_train)"
      ],
      "metadata": {
        "id": "4w73us5qyRGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root = create_tree(root, X_train, y_train)"
      ],
      "metadata": {
        "id": "-6uamBxbyWmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the predictions through test data\n",
        "output_str = \"\"\n",
        "\n",
        "for i in range(len(X_test)):\n",
        "\tif predict(root, X_test[i]) == 'N':\n",
        "\t\toutput_str += str(0) + \" \"\n",
        "\telse:\n",
        "\t\toutput_str += str(1) + \" \"\n",
        "\n",
        "print(output_str)\t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScqD2SE0yp54",
        "outputId": "fe2face3-7b29-4c6b-bdbd-f3acc499bff8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0 1 1 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-rvpa7blyz3m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}